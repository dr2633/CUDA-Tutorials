Building ML Systems for a Trillion Trillion Floating Point Operations 
https://www.youtube.com/watch?v=139UPjoq7Kw

300k GPU clousters, Nuclear power to serve these data centers 

All of this is to do an ever-growing amount of floating point operations 

https://epoch.ai/blog/trends-in-gpu-price-performance

Leading models use 1e26 floating point operations (trillion TeraFlops)

These operations need to be instantiated on hardware 

LLM API 
https://docs.api.nvidia.com/nim/reference/llm-apis
